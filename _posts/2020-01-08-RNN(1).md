---
layout: post
title: "Rerruent Neural Networks"
subtitle: "with Keras 가이드"
categories : [ML]
date: 2020-1-8 16:00:00 -0900
background: '/img/posts/06.jpg'
---

# RNN
  Recurrent neural networks는 순서가 있는 시계열 데이터에 대한 학습이 가능한 구조이다. 이 같은 구조는 시간의 흐름에 따른 주가 예측이나, 자연어 처리, 음성 처리 등에서 사용될 수 있다.
 
## 구성하는 방법 : Keras RNN API
Keras 자체의 `tf.keras.layers.RNN`, `tf.keras.layers.LSTM`, `tf.keras.layers.GRU` 를 통해서 쉽게 RNN을 구성할 수 있다.

## Setup
``` Python
from __future__ import absolute_import, division, print_function, unicode_literals

import collections
import matplotlib.pyplot as plt
import numpy as np

import tensorflow as tf

from tensorflow.keras import layers
```

## Build a simple model
 Keras에는 3가지 built-in RNN layer가 있는데, 다음과 같다.
 1. `tf.keras.layers.SimpleRNN` : 이전 Cell의 출력이 다음 Cell로 입력되는 fully connected RNN 이다.
 2. `tf.kearas.layers.GRU` : 'Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation' 에서 처음 소개된 모델.
 3. `tf.keras.layers.LSTM` : 'Long Short-Term Memory'에서 처음 소개된 모델.

# Keras 기초
 먼저 RNN 을 구성하기 전에 Keras의 기본적인 사용법을 알아보자. 


## tf.keras.Sequetial()
 `tf.keras.Sequetial` 는 층(layer)을 차례대로 쌓은 모델이다. 객체를 생성하고, add를 통해 층을 추가할 수 있다.

 ``` Python
model = tf.keras.Sequential()
model.add(layers.Dense(64, activation='relu')) # input cell이 64
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10, activation='softmax')) # 10개의 출력 유닛을 가진 소프트맥스 층을 추가
 ```
  Sequential이 아닌 모델을 사용하기 위해서는 [케라스 함수영 API 가이드](https://www.tensorflow.org/guide/keras/functional?hl=ko) 를 참고해야한다.

## tf.keras.layers.Dense()
 tf.keras.layers.Dense()의 output은 activation(dot(input, kernel) + bias)꼴이다. 여기서 kernel은 weight를 말한다. activation function은 `relu`, `softmax` 등으로 지정할 수 있다.
``` Python
    model.add(Dense(32, input_shape=(16, )))
    model.add(Dense(32)) # input shape 따로 명기x 
```
  위와 같이 선언하면 input shape는 (*, 16)형태이고, output은 (*, 32)형태이다.
 두번째 layer부터는 input shape를 따로 명기하지 않아도된다.


## tf.keras.layers 층 설정
 `tf.keras.layers` 하위 클래스의 공통적인 생성자 매개변수는 다음과 같다.
- `activation` : 활성화 함수 지정. 기본값은 활성화 함수를 적용하지 않는것. 즉 단순 XW + b 의 출력.
- `kernel_initializer`와 `bias_initializer` : weight와 bias를 초기화하는 방법을 지정함. 기본값은 "glorot_uniform" 초기화임.
- `kernel_regularizer`와 `bias_regularizer` : L1 또는 L2 규제(regularization)와 같이 층의 가중치(커널과 절편)에 적용할 규제 방법을 지정. 기본값은 규제를 적용하지 않는 것이다.


``` Python
model = tf.keras.Sequential()
# Add an Embedding layer expecting input vocab of size 1000, and
# output embedding dimension of size 64.
model.add(layers.Embedding(input_dim=1000, output_dim=64))

# Add a LSTM layer with 128 internal units.
model.add(layers.LSTM(128))

# Add a Dense layer with 10 units and softmax activation.
model.add(layers.Dense(10, activation='softmax'))

model.summary()
```


## 훈련 준비
 위에서 처럼(`model = tf.keras.Sequential`)  모델을 구성한 후.. `compile` 메소드를 통해 학습을 설정할 수 있다.
``` Python
model.compile(optimizer=tf.keras.optimizers.Adam(0.001),
            loss = 'categorical_crossentropy',
            metrics = ['accuracy'])
```
 - `optimizer` : 훈련과정을 설정함. tf.keras.optimizers.Adam 이나 tf.keras.optimizers.SGD와 같은 tf.keras.optimizers 아래의 옵티마이저 객체를 전달하거나, 'adam'이나 'sgd'와 같이 문자열로도 지정 가능하다. 
 - `loss` : 손실함수를 설정한다. `mse`나 `categorical_crossentropy`, `binary_crossentropy` 등이 자주 사용된다. 또는 tf.keras.losses 모듈 아래의 호출 가능한 객체를 전달할 수 있다.

 - `metrics` : 훈련을 모니터링하기 위해 사용. 이름 또는 `tf.keras.metrics`모듈 아래 객체를 사용할 수 있다.


## 넘파이 데이터를 사용한 훈련
 데이터셋이 작은 경우 Numpy 배열을 '메모리'에 적재하여 훈련할 수 있다.  
`fit` 메소드를 통해서 훈련데이터를 학습할 수 있다. 
 
``` Python
import numpy as np

data = np.random.random((1000, 32)) # 임의 입력데이터
labels = np.random.random((1000, 10)) # 임의 label 데이터

model.fit(data, labels, epochs=10, batch_size=32) # 모델 학습
```
 fit (tf.keras.Model.fit) 에는 세 개의 중요한 매개변수 존재.
 1. `epochs` : 전체 데이터 학습 횟수.
 2. `batch_size` : 데이터를 나누는 단위.
 3. `validation_data` : (입력, 레이블) 튜플을 여기로 전달하면, 에포크가 끝날 때마다 데이터의 손실과 측정 지표를 출력한다.
  
fit 매개변수 예시
``` Python
model.fit(data, labels, epochs=10, batch_size=32,
          validation_data=(val_data, val_labels))
```

## tf.data.Dataset 을 사용한 훈련
 ``` Python
dataset = tf.data.Dataset.from_tensor_slices((data, labels))
dataset = dataset.batch(32)

val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))
val_dataset = val_dataset.batch(32)

model.fit(dataset, epochs=10,
          validation_data=val_dataset)
 ```
 여기서 dataset.batch(32)는 32 개의 데이터를 하나의 batch로 지정한다는 의미이다.

## 평가와 예측
 `tf.keras.Model.evaluate`와 `tf.keras.Model.predict` 메소드를 사용한다.
 ``` python
model.evaluate(data, labels, batch_size=32)
model.evaluate(dataset, steps=30)

result = model.predict(data, batch_size=32)
print(result.shape)
 ```
predict 메소드는 마지막 층의 출력을 넘파이 배열로 반환한다.

## 고급모델 만들기
[Keras 함수형 API](https://www.tensorflow.org/guide/keras/overview?hl=ko#%EA%B3%A0%EA%B8%89_%EB%AA%A8%EB%8D%B8_%EB%A7%8C%EB%93%A4%EA%B8%B0)  참고

## 콜백
 > 콜백(callback)은 훈련하는 동안 모델의 동작을 변경하고 확장하기 위해 전달하는 객체입니다. 자신만의 콜백을 작성하거나 다음과 같은 내장 `tf.keras.callbacks`을 사용할 수 있습니다:

  fit 메소드에 `callbacks = `과 같이 전달하여 사용할 수 있다.

`tf.keras.callbacks.ModelCheckpoint`: 일정 간격으로 모델의 체크포인트를 저장합니다.
`tf.keras.callbacks.LearningRateScheduler`: 학습률(learning rate)을 동적으로 변경합니다.
`tf.keras.callbacks.EarlyStopping`: 검증 성능이 향상되지 않으면 훈련을 중지합니다.
`tf.keras.callbacks.TensorBoard`: 텐서보드를 사용하여 모델을 모니터링합니다.

## 모델의 저장과 복원
### 가중치만 저장
``` python
# 가중치를 텐서플로의 체크포인트 파일로 저장합니다.
model.save_weights('./weights/my_model')

# 모델의 상태를 복원합니다.
# 모델의 구조가 동일해야 합니다.
model.load_weights('./weights/my_model')
```
### 전체 저장
``` python
# 전체 모델을 HDF5 파일로 저장합니다.
model.save('my_model.h5')

# 가중치와 옵티마이저를 포함하여 정확히 같은 모델을 다시 만듭니다.
model = tf.keras.models.load_model('my_model.h5')

```
## 분산 처리
### 다중 GPU
 현재는 `tf.distribute.MirroredStrategy`가 유일하게 지원되는 분산전략이라고 한다.
`Strategy`의 `.scope()` 안에서 옵티마이저 객체 생성, 모델 구성, 컴파일해야한다. 훈련은 일반 코드와 똑같이 하면된다.
``` python
strategy = tf.distribute.MirroredStrategy()

with strategy.scope():
  model = tf.keras.Sequential()
  model.add(layers.Dense(16, activation='relu', input_shape=(10,)))
  model.add(layers.Dense(1, activation='sigmoid'))

  optimizer = tf.keras.optimizers.SGD(0.2)

  model.compile(loss='binary_crossentropy', optimizer=optimizer)

model.summary()

model.fit(dataset, epochs=1)
```




# 출처
[Tensorflow RNN Guide](https://www.tensorflow.org/guide/keras/rnn?hl=ko)  
[Keras 빠르게 훑어보기](https://www.tensorflow.org/guide/keras/overview?hl=ko)  

등 Tensorflow 공식 가이드를 참고하여 작성하였습니다.
